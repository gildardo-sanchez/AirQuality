{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ccaedd",
   "metadata": {},
   "source": [
    "# Training a MLP\n",
    "\n",
    "In this example, we are going to create, train and score a Regressor\n",
    "\n",
    "Dataset Information:\n",
    "\n",
    "The dataset contains 9358 instances of hourly averaged responses from an array of 5 metal oxide chemical sensors embedded in an Air Quality Chemical Multisensor Device. The device was located on the field in a significantly polluted area, at road level,within an Italian city. Data were recorded from March 2004 to February 2005 (one year)representing the longest freely available recordings of on field deployed air quality chemical sensor devices responses. Ground Truth hourly averaged concentrations for CO, Non Metanic Hydrocarbons, Benzene, Total Nitrogen Oxides (NOx) and Nitrogen Dioxide (NO2) and were provided by a co-located reference certified analyzer. Evidences of cross-sensitivities as well as both concept and sensor drifts are present as described in De Vito et al., Sens. And Act. B, Vol. 129,2,2008 (citation required) eventually affecting sensors concentration estimation capabilities. Missing values are tagged with -200 value. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac11dce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da44dd4a",
   "metadata": {},
   "source": [
    "Import dataset, separate attribute columns from output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fec9f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       CO\n",
      "0     2.9\n",
      "1     4.8\n",
      "2     6.9\n",
      "3     6.1\n",
      "4     3.9\n",
      "...   ...\n",
      "7389  2.7\n",
      "7390  2.5\n",
      "7391  1.5\n",
      "7392  1.6\n",
      "7393  1.2\n",
      "\n",
      "[7394 rows x 1 columns]\n",
      "      PT08.S1  PT08.S2  PT08.S3  PT08.S4  PT08.S5     T    RH      AH\n",
      "0        1383     1020     1008     1719     1104   9.8  67.6  0.8185\n",
      "1        1581     1319      799     2083     1409  10.3  64.2  0.8065\n",
      "2        1776     1488      702     2333     1704   9.7  69.3  0.8319\n",
      "3        1640     1404      743     2191     1654   9.6  67.8  0.8133\n",
      "4        1313     1076      957     1707     1285   9.1  64.0  0.7419\n",
      "...       ...      ...      ...      ...      ...   ...   ...     ...\n",
      "7389     1248     1018      599     1289     1167  19.9  33.0  0.7608\n",
      "7390     1180      894      636     1200     1372  17.5  40.7  0.8073\n",
      "7391     1102      812      693     1178     1042  16.4  46.6  0.8642\n",
      "7392     1116      803      696     1173     1055  15.5  49.0  0.8579\n",
      "7393     1100      769      722     1147     1049  14.3  52.5  0.8497\n",
      "\n",
      "[7394 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load data. The original dataset includes names in first row\n",
    "dataset = pd.read_csv(\"AirQuality_clean2.csv\")\n",
    "\n",
    "# Separate the class from the attributes\n",
    "target = pd.DataFrame(dataset, columns= ['CO'])\n",
    "\n",
    "print (target)\n",
    "\n",
    "attributes= dataset.loc[ : , dataset.columns != 'CO']\n",
    "print(attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdd9242",
   "metadata": {},
   "source": [
    "Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c426d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into  training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test= train_test_split(\n",
    "    attributes,target,test_size=0.33, random_state=50)\n",
    "\n",
    "#print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb20ce6",
   "metadata": {},
   "source": [
    "Train an MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3afe57f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train one model with raw data to establish a reference.\n",
    "# In this case, we will train a MLP\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#Initializing the MLPRegressor\n",
    "regr = MLPRegressor(hidden_layer_sizes=(100,50,10), max_iter=1000,\n",
    "                           activation = 'relu',solver='adam',random_state=1)\n",
    "\n",
    "#Fitting the training data to the network\n",
    "regr.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Predicting y for X_val\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afc1735",
   "metadata": {},
   "source": [
    "Compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab71f733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6901872795820116"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84693a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
